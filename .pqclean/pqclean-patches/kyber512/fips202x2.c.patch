--- work/kyber512/scheme/fips202x2.c
+++ work-patched/kyber512/scheme/fips202x2.c
@@ -52,20 +52,20 @@
 #define vxor(c, a, b) c = veorq_u64(a, b);
 // Rotate by n bit ((a << offset) ^ (a >> (64-offset)))
 #define vROL(out, a, offset)    \
-  out = vshlq_n_u64(a, offset); \
-  out = vsriq_n_u64(out, a, 64 - offset);
+    (out) = vshlq_n_u64(a, offset); \
+    (out) = vsriq_n_u64(out, a, 64 - (offset));
 // Xor chain: out = a ^ b ^ c ^ d ^ e
 #define vXOR4(out, a, b, c, d, e) \
-  out = veorq_u64(a, b);          \
-  out = veorq_u64(out, c);        \
-  out = veorq_u64(out, d);        \
-  out = veorq_u64(out, e);
+    (out) = veorq_u64(a, b);          \
+    (out) = veorq_u64(out, c);        \
+    (out) = veorq_u64(out, d);        \
+    (out) = veorq_u64(out, e);
 // Not And c = ~a & b
 // #define vbic(c, a, b) c = vbicq_u64(b, a);
 // Xor Not And: out = a ^ ( (~b) & c)
 #define vXNA(out, a, b, c) \
-  out = vbicq_u64(c, b);   \
-  out = veorq_u64(out, a);
+    (out) = vbicq_u64(c, b);   \
+    (out) = veorq_u64(out, a);
 // Rotate by 1 bit, then XOR: a ^ ROL(b): SHA1 instruction, not support
 #define vrxor(c, a, b) c = vrax1q_u64(a, b);
 // End Define
@@ -95,7 +95,8 @@
     (uint64_t)0x8000000080008081ULL,
     (uint64_t)0x8000000000008080ULL,
     (uint64_t)0x0000000080000001ULL,
-    (uint64_t)0x8000000080008008ULL};
+    (uint64_t)0x8000000080008008ULL
+};
 
 /*************************************************
 * Name:        KeccakF1600_StatePermutex2
@@ -104,12 +105,12 @@
 *
 * Arguments:   - uint64_t *state: pointer to input/output Keccak state
 **************************************************/
-extern void f1600x2(v128*, const uint64_t*);
+extern void PQCLEAN_NAMESPACE_f1600x2(v128*, const uint64_t*);
 static inline
 void KeccakF1600_StatePermutex2(v128 state[25])
 {
 #if (__APPLE__ && __ARM_FEATURE_CRYPTO) || (__ARM_FEATURE_SHA3) /* although not sure what is being implemented, we find something fast */
-  f1600x2(state, neon_KeccakF_RoundConstants);
+  PQCLEAN_NAMESPACE_f1600x2(state, neon_KeccakF_RoundConstants);
 #else
   v128 Aba, Abe, Abi, Abo, Abu;
   v128 Aga, Age, Agi, Ago, Agu;
@@ -401,98 +402,93 @@
                      const uint8_t *in0,
                      const uint8_t *in1,
                      size_t inlen,
-                     uint8_t p)
-{
-  size_t i, pos = 0;
+                     uint8_t p) {
+    size_t i, pos = 0;
 
-  // Declare SIMD registers
-  v128 tmp, mask;
-  uint64x1_t a, b;
-  uint64x2_t a1, b1, atmp1, btmp1;
-  uint64x2x2_t a2, b2, atmp2, btmp2;
-  // End
+    // Declare SIMD registers
+    v128 tmp, mask;
+    uint64x1_t a, b;
+    uint64x2_t a1, b1, atmp1, btmp1;
+    uint64x2x2_t a2, b2, atmp2, btmp2;
+    // End
 
-  for (i = 0; i < 25; ++i)
-    s[i] = vdupq_n_u64(0);
+    for (i = 0; i < 25; ++i) {
+        s[i] = vdupq_n_u64(0);
+    }
 
-  // Load in0[i] to register, then in1[i] to register, exchange them
-  while (inlen >= r)
-  {
-    for (i = 0; i < r / 8 - 1; i += 4)
-    {
-      a2 = vld1q_u64_x2((uint64_t *)&in0[pos]);
-      b2 = vld1q_u64_x2((uint64_t *)&in1[pos]);
-      // BD = zip1(AB and CD)
-      atmp2.val[0] = vzip1q_u64(a2.val[0], b2.val[0]);
-      atmp2.val[1] = vzip1q_u64(a2.val[1], b2.val[1]);
-      // AC = zip2(AB and CD)
-      btmp2.val[0] = vzip2q_u64(a2.val[0], b2.val[0]);
-      btmp2.val[1] = vzip2q_u64(a2.val[1], b2.val[1]);
-
-      vxor(s[i + 0], s[i + 0], atmp2.val[0]);
-      vxor(s[i + 1], s[i + 1], btmp2.val[0]);
-      vxor(s[i + 2], s[i + 2], atmp2.val[1]);
-      vxor(s[i + 3], s[i + 3], btmp2.val[1]);
+    // Load in0[i] to register, then in1[i] to register, exchange them
+    while (inlen >= r) {
+        for (i = 0; i < r / 8 - 1; i += 4) {
+            a2 = vld1q_u64_x2((uint64_t *)&in0[pos]);
+            b2 = vld1q_u64_x2((uint64_t *)&in1[pos]);
+            // BD = zip1(AB and CD)
+            atmp2.val[0] = vzip1q_u64(a2.val[0], b2.val[0]);
+            atmp2.val[1] = vzip1q_u64(a2.val[1], b2.val[1]);
+            // AC = zip2(AB and CD)
+            btmp2.val[0] = vzip2q_u64(a2.val[0], b2.val[0]);
+            btmp2.val[1] = vzip2q_u64(a2.val[1], b2.val[1]);
+
+            vxor(s[i + 0], s[i + 0], atmp2.val[0]);
+            vxor(s[i + 1], s[i + 1], btmp2.val[0]);
+            vxor(s[i + 2], s[i + 2], atmp2.val[1]);
+            vxor(s[i + 3], s[i + 3], btmp2.val[1]);
+
+            pos += 8 * 2 * 2;
+        }
+        // Last iteration
+        i = r / 8 - 1;
+        a = vld1_u64((uint64_t *)&in0[pos]);
+        b = vld1_u64((uint64_t *)&in1[pos]);
+        tmp = vcombine_u64(a, b);
+        vxor(s[i], s[i], tmp);
+        pos += 8;
 
-      pos += 8 * 2 * 2;
+        KeccakF1600_StatePermutex2(s);
+        inlen -= r;
     }
-    // Last iteration
-    i = r / 8 - 1;
-    a = vld1_u64((uint64_t *)&in0[pos]);
-    b = vld1_u64((uint64_t *)&in1[pos]);
-    tmp = vcombine_u64(a, b);
-    vxor(s[i], s[i], tmp);
-    pos += 8;
-
-    KeccakF1600_StatePermutex2(s);
-    inlen -= r;
-  }
 
-  i = 0;
-  while (inlen >= 16)
-  {
-    a1 = vld1q_u64((uint64_t *)&in0[pos]);
-    b1 = vld1q_u64((uint64_t *)&in1[pos]);
-    // BD = zip1(AB and CD)
-    atmp1 = vzip1q_u64(a1, b1);
-    // AC = zip2(AB and CD)
-    btmp1 = vzip2q_u64(a1, b1);
-
-    vxor(s[i + 0], s[i + 0], atmp1);
-    vxor(s[i + 1], s[i + 1], btmp1);
-
-    i += 2;
-    pos += 8 * 2;
-    inlen -= 8 * 2;
-  }
+    i = 0;
+    while (inlen >= 16) {
+        a1 = vld1q_u64((uint64_t *)&in0[pos]);
+        b1 = vld1q_u64((uint64_t *)&in1[pos]);
+        // BD = zip1(AB and CD)
+        atmp1 = vzip1q_u64(a1, b1);
+        // AC = zip2(AB and CD)
+        btmp1 = vzip2q_u64(a1, b1);
+
+        vxor(s[i + 0], s[i + 0], atmp1);
+        vxor(s[i + 1], s[i + 1], btmp1);
+
+        i += 2;
+        pos += 8 * 2;
+        inlen -= 8 * 2;
+    }
 
-  if (inlen >= 8)
-  {
-    a = vld1_u64((uint64_t *)&in0[pos]);
-    b = vld1_u64((uint64_t *)&in1[pos]);
-    tmp = vcombine_u64(a, b);
-    vxor(s[i], s[i], tmp);
+    if (inlen >= 8) {
+        a = vld1_u64((uint64_t *)&in0[pos]);
+        b = vld1_u64((uint64_t *)&in1[pos]);
+        tmp = vcombine_u64(a, b);
+        vxor(s[i], s[i], tmp);
+
+        i++;
+        pos += 8;
+        inlen -= 8;
+    }
 
-    i++;
-    pos += 8;
-    inlen -= 8;
-  }
+    if (inlen) {
+        a = vld1_u64((uint64_t *)&in0[pos]);
+        b = vld1_u64((uint64_t *)&in1[pos]);
+        tmp = vcombine_u64(a, b);
+        mask = vdupq_n_u64((1ULL << (8 * inlen)) - 1);
+        tmp = vandq_u64(tmp, mask);
+        vxor(s[i], s[i], tmp);
+    }
 
-  if (inlen)
-  {
-    a = vld1_u64((uint64_t *)&in0[pos]);
-    b = vld1_u64((uint64_t *)&in1[pos]);
-    tmp = vcombine_u64(a, b);
-    mask = vdupq_n_u64((1ULL << (8 * inlen)) - 1);
-    tmp = vandq_u64(tmp, mask);
+    tmp = vdupq_n_u64((uint64_t)p << (8 * inlen));
     vxor(s[i], s[i], tmp);
-  }
-
-  tmp = vdupq_n_u64((uint64_t)p << (8 * inlen));
-  vxor(s[i], s[i], tmp);
 
-  mask = vdupq_n_u64(1ULL << 63);
-  vxor(s[r / 8 - 1], s[r / 8 - 1], mask);
+    mask = vdupq_n_u64(1ULL << 63);
+    vxor(s[r / 8 - 1], s[r / 8 - 1], mask);
 }
 
 /*************************************************
@@ -563,15 +559,15 @@
 void shake128x2_absorb(keccakx2_state *state,
                        const uint8_t *in0,
                        const uint8_t *in1,
-                       size_t inlen){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  keccakx2_absorb(state->s, SHAKE128_RATE, in0, in1, inlen, 0x1F);
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+                       size_t inlen) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    keccakx2_absorb(state->s, SHAKE128_RATE, in0, in1, inlen, 0x1F);
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }
 
 /*************************************************
@@ -589,15 +585,15 @@
 void shake128x2_squeezeblocks(uint8_t *out0,
                               uint8_t *out1,
                               size_t nblocks,
-                              keccakx2_state *state){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  keccakx2_squeezeblocks(out0, out1, nblocks, SHAKE128_RATE, state->s);
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+                              keccakx2_state *state) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    keccakx2_squeezeblocks(out0, out1, nblocks, SHAKE128_RATE, state->s);
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }
 
 /*************************************************
@@ -613,15 +609,15 @@
 void shake256x2_absorb(keccakx2_state *state,
                        const uint8_t *in0,
                        const uint8_t *in1,
-                       size_t inlen){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  keccakx2_absorb(state->s, SHAKE256_RATE, in0, in1, inlen, 0x1F);
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+                       size_t inlen) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    keccakx2_absorb(state->s, SHAKE256_RATE, in0, in1, inlen, 0x1F);
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }
 
 /*************************************************
@@ -639,15 +635,15 @@
 void shake256x2_squeezeblocks(uint8_t *out0,
                               uint8_t *out1,
                               size_t nblocks,
-                              keccakx2_state *state){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  keccakx2_squeezeblocks(out0, out1, nblocks, SHAKE256_RATE, state->s);
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+                              keccakx2_state *state) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    keccakx2_squeezeblocks(out0, out1, nblocks, SHAKE256_RATE, state->s);
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }
 
 /*************************************************
@@ -665,35 +661,33 @@
                 size_t outlen,
                 const uint8_t *in0,
                 const uint8_t *in1,
-                size_t inlen){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  unsigned int i;
-  size_t nblocks = outlen / SHAKE128_RATE;
-  uint8_t t[2][SHAKE128_RATE];
-  keccakx2_state state;
-
-  shake128x2_absorb(&state, in0, in1, inlen);
-  shake128x2_squeezeblocks(out0, out1, nblocks, &state);
-
-  out0 += nblocks * SHAKE128_RATE;
-  out1 += nblocks * SHAKE128_RATE;
-  outlen -= nblocks * SHAKE128_RATE;
-
-  if (outlen)
-  {
-    shake128x2_squeezeblocks(t[0], t[1], 1, &state);
-    for (i = 0; i < outlen; ++i)
-    {
-      out0[i] = t[0][i];
-      out1[i] = t[1][i];
+                size_t inlen) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    unsigned int i;
+    size_t nblocks = outlen / SHAKE128_RATE;
+    uint8_t t[2][SHAKE128_RATE];
+    keccakx2_state state;
+
+    shake128x2_absorb(&state, in0, in1, inlen);
+    shake128x2_squeezeblocks(out0, out1, nblocks, &state);
+
+    out0 += nblocks * SHAKE128_RATE;
+    out1 += nblocks * SHAKE128_RATE;
+    outlen -= nblocks * SHAKE128_RATE;
+
+    if (outlen) {
+        shake128x2_squeezeblocks(t[0], t[1], 1, &state);
+        for (i = 0; i < outlen; ++i) {
+            out0[i] = t[0][i];
+            out1[i] = t[1][i];
+        }
     }
-  }
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }
 
 /*************************************************
@@ -711,33 +705,31 @@
                 size_t outlen,
                 const uint8_t *in0,
                 const uint8_t *in1,
-                size_t inlen){
-#ifdef PROFILE_HASHING
-  uint64_t t0 = hal_get_time();
-#endif
-  unsigned int i;
-  size_t nblocks = outlen / SHAKE256_RATE;
-  uint8_t t[2][SHAKE256_RATE];
-  keccakx2_state state;
-
-  shake256x2_absorb(&state, in0, in1, inlen);
-  shake256x2_squeezeblocks(out0, out1, nblocks, &state);
-
-  out0 += nblocks * SHAKE256_RATE;
-  out1 += nblocks * SHAKE256_RATE;
-  outlen -= nblocks * SHAKE256_RATE;
-
-  if (outlen)
-  {
-    shake256x2_squeezeblocks(t[0], t[1], 1, &state);
-    for (i = 0; i < outlen; ++i)
-    {
-      out0[i] = t[0][i];
-      out1[i] = t[1][i];
+                size_t inlen) {
+    #ifdef PROFILE_HASHING
+    uint64_t t0 = hal_get_time();
+    #endif
+    unsigned int i;
+    size_t nblocks = outlen / SHAKE256_RATE;
+    uint8_t t[2][SHAKE256_RATE];
+    keccakx2_state state;
+
+    shake256x2_absorb(&state, in0, in1, inlen);
+    shake256x2_squeezeblocks(out0, out1, nblocks, &state);
+
+    out0 += nblocks * SHAKE256_RATE;
+    out1 += nblocks * SHAKE256_RATE;
+    outlen -= nblocks * SHAKE256_RATE;
+
+    if (outlen) {
+        shake256x2_squeezeblocks(t[0], t[1], 1, &state);
+        for (i = 0; i < outlen; ++i) {
+            out0[i] = t[0][i];
+            out1[i] = t[1][i];
+        }
     }
-  }
-#ifdef PROFILE_HASHING
-  uint64_t t1 = hal_get_time();
-  hash_cycles += (t1-t0);
-#endif
+    #ifdef PROFILE_HASHING
+    uint64_t t1 = hal_get_time();
+    hash_cycles += (t1 - t0);
+    #endif
 }

